% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/querychat.R
\name{querychat_init}
\alias{querychat_init}
\title{Call this once outside of any server function}
\usage{
querychat_init(
  df,
  ...,
  table_name = deparse(substitute(df)),
  greeting = NULL,
  data_description = NULL,
  extra_instructions = NULL,
  prompt_template = NULL,
  system_prompt = querychat_system_prompt(df, table_name, ..., data_description =
    data_description, extra_instructions = extra_instructions, prompt_template =
    prompt_template),
  create_chat_func = purrr::partial(ellmer::chat_openai, model = "gpt-4o")
)
}
\arguments{
\item{df}{A data frame.}

\item{...}{Additional arguments passed to the \code{querychat_system_prompt()}
function, such as \code{categorical_threshold}. If a
\code{system_prompt} argument is provided, the \code{...} arguments will be silently
ignored.}

\item{table_name}{A string containing a valid table name for the data frame,
that will appear in SQL queries. Ensure that it begins with a letter, and
contains only letters, numbers, and underscores. By default, querychat will
try to infer a table name using the name of the \code{df} argument.}

\item{greeting}{Optional string or existing file path. The contents
should be in plain text or Markdown format, containing the initial message
to display to the user upon first loading the chatbot. If not provided, the
LLM will be invoked at the start of the conversation to generate one.}

\item{data_description}{Optional string or existing file path. The contents
should be in plain text or Markdown format, containing a description of the
data frame or any additional context that might be helpful in understanding
the data. This will be included in the system prompt for the chat model.}

\item{extra_instructions}{Optional string or existing file path. The contents
should be in plain text or Markdown format, containing any additional
instructions for the chat model. These will be appended at the end of the
system prompt.}

\item{prompt_template}{Optional string or existing file path. If \code{NULL}, the
default prompt file in the package will be used. The contents should
contain a whisker template for the system prompt, with placeholders for
\code{{{schema}}}, \code{{{data_description}}}, and \code{{{extra_instructions}}}.}

\item{system_prompt}{A string containing the system prompt for the chat model.
The default uses \code{querychat_system_prompt()} to generate a generic prompt,
which you can enhance via the \code{data_description} and \code{extra_instructions}
arguments.}

\item{create_chat_func}{A function that takes a system prompt and returns a
chat object. The default uses \code{ellmer::chat_openai()}.}
}
\value{
An object that can be passed to \code{querychat_server()} as the
\code{querychat_config} argument. By convention, this object should be named
\code{querychat_config}.
}
\description{
This will perform one-time initialization that can then be shared by all
Shiny sessions in the R process.
}
