---
title: Introduction
lightbox: true
---

```{=html}
<style>h1.title { display:none; }</style>
```

<img src="/images/querychat.png" alt="querychat website banner image" class="d-block mx-auto mb-3" style="max-width:100%; max-height:425px"/>

<p class="fs-2 lead mt-3 mb-3 text-center" style="max-width: 600px; margin: auto;">
Explore data using natural language queries
</p>

<div class="d-flex justify-content-center mb-3">
<!-- badges start -->
<a href="https://pypi.org/project/querychat/"><img alt="PyPI" src="https://img.shields.io/pypi/v/querychat?logo=python&logoColor=white&color=orange"></a>
<a href="https://choosealicense.com/licenses/mit/"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="MIT License"></a>
<a href="https://pypi.org/project/querychat"><img src="https://img.shields.io/pypi/pyversions/querychat.svg" alt="versions"></a>
<a href="https://github.com/posit-dev/querychat"><img src="https://github.com/posit-dev/querychat/actions/workflows/py-test.yml/badge.svg?branch=main" alt="Python Tests"></a>
<!-- badges end -->
</div>

querychat facilitates safe and reliable natural language exploration of tabular data, powered by SQL and large language models (LLMs). For users, it offers an intuitive web application where they can quickly ask questions of their data and receive verifiable data-driven answers. As a developer, you can access the chat UI component, generated SQL queries, and filtered data to build custom applications that integrate natural language querying into your data workflows.

## Installation

Install the latest stable release [from PyPI](https://pypi.org/project/querychat/):

```bash
pip install querychat
```

## Quick start

The main entry point is the `QueryChat` class. It requires a [data source](data-sources.qmd) (e.g., pandas, polars, etc) and a name for the data. It also accepts optional parameters to customize the behavior, such as the `client` [model](models.qmd).
The quickest way to start chatting is to call the `.app()` method, which by default returns a [Shiny](https://shiny.posit.co/py/) app:

```{.python filename="app.py"}
from querychat import QueryChat
from querychat.data import titanic

qc = QueryChat(titanic(), "titanic")
app = qc.app()
```

::: {.callout-tip}
### Prefer Streamlit, Gradio, or Dash?

querychat supports multiple [web frameworks](#web-frameworks)â€”just change the import.
:::

With an API key set[^api-key], save the code to `app.py` and run it:

```bash
shiny run --reload app.py
```

[^api-key]: By default, querychat uses OpenAI to power the chat experience. So, for this example to work, you'll need [an OpenAI API key](https://platform.openai.com/). See the [Models](models.qmd) page for details on how to set up credentials for other model providers.

Once running, you'll notice 3 main views:

1. A sidebar chat with suggestions on where to start exploring.
2. A data table that updates to reflect filtering and sorting queries.
3. The SQL query behind the data table, for transparency and reproducibility.

![](/images/quickstart.png){fig-alt="Screenshot of querychat's app with the titanic dataset." class="lightbox shadow rounded mb-3"}

Suppose we pick a suggestion like "Show me passengers who survived". Since this is a filtering operation, both the data table and SQL query update accordingly.

![](/images/quickstart-filter.png){fig-alt="Screenshot of the querychat's app with the titanic dataset filtered to passengers who survived." class="lightbox shadow rounded mb-3"}

querychat can also handle more general questions about the data that require calculations and aggregations. For example, we can ask "What is the average age of passengers who survived?". The LLM will generate the SQL query to perform the calculation, querychat will execute it, and return the result in the chat:

![](/images/quickstart-summary.png){fig-alt="Screenshot of the querychat's app with a summary statistic inlined in the chat." class="lightbox shadow rounded mb-3"}

## Web frameworks

While the examples above use [Shiny](https://shiny.posit.co/py/), querychat also supports [Streamlit](https://streamlit.io/), [Gradio](https://gradio.app/), and [Dash](https://dash.plotly.com/). Each framework has its own `QueryChat` class under the relevant sub-module, but the methods and properties are mostly consistent across all of them.

::: {.panel-tabset}

### Streamlit

```{.python}
from querychat.streamlit import QueryChat
from querychat.data import titanic

qc = QueryChat(titanic(), "titanic")
qc.app()
```

### Gradio

```{.python}
from querychat.gradio import QueryChat
from querychat.data import titanic

qc = QueryChat(titanic(), "titanic")
qc.app().launch()
```

### Dash

```{.python}
from querychat.dash import QueryChat
from querychat.data import titanic

qc = QueryChat(titanic(), "titanic")
qc.app().run()
```

:::

Install the framework you need with optional dependencies:

```bash
pip install "querychat[streamlit]"  # or [gradio] or [dash]
```

## Build custom apps

querychat is designed to be highly extensible -- it provides programmatic access to the chat interface, the filtered/sorted data frame, SQL queries, and more.
This makes it easy to build custom web apps that leverage natural language interaction with your data.
For example, [here](https://github.com/posit-conf-2025/llm/blob/main/_solutions/25_querychat/25_querychat_02-end-app.R)'s a bespoke app for exploring Airbnb listings in Ashville, NC:

![](/images/airbnb.png){fig-alt="A custom app for exploring Airbnb listings, powered by querychat." class="lightbox shadow rounded mb-3"}

To learn more, see the build guides for your framework: [Shiny](build.qmd), [Streamlit](build-streamlit.qmd), [Gradio](build-gradio.qmd), or [Dash](build-dash.qmd).

## How it works

querychat uses LLMs to translate natural language into SQL queries. Models of all sizes, from small ones you can run locally to large frontier models from major AI providers, are remarkably effective at this task. But even the best models need to understand your data's overall structure to perform well.

To address this, querychat includes schema metadata -- column names, types, ranges, categorical values -- in the LLM's [system prompt](context.qmd). Importantly, querychat **does not** send raw data to the LLM; it shares only enough structural information for the model to generate accurate queries. When the LLM produces a query, querychat executes it in a SQL database (DuckDB[^duckdb], by default) to obtain precise results.

This design makes querychat reliable, safe, and reproducible:

- **Reliable**: query results come from a real database, not LLM-generated summaries -- so outputs are precise, verifiable, and less vulnerable to hallucination[^hallucination].
- **Safe**: querychat's tools are read-only by design, avoiding destructive actions on your data.[^permissions]
- **Reproducible**: generated SQL can be exported and re-run in other environments, so your analysis isn't locked into a single tool.

::: callout-important
**Data privacy**

See the [Provide context](context.qmd) and [Tools](tools.qmd)  articles for more details on exactly what information is provided to the LLM and how customize it.
:::

[^duckdb]: DuckDB is extremely fast and has a surprising number of [statistical functions](https://duckdb.org/docs/stable/sql/functions/aggregates.html#statistical-aggregates).

[^hallucination]: The [query tool](tools.qmd) gives query results to the model for context and interpretation. Thus, there is *some* potential that the model to mis-interpret those results. 

[^permissions]: To fully guarantee no destructive actions on your production database, ensure querychat's database permissions are read-only.



## Next steps

From here, you might want to learn more about:

- [Models](models.qmd): customize the LLM behind querychat.
- [Data sources](data-sources.qmd): different data sources you can use with querychat.
- [Provide context](context.qmd): provide the LLM with the context it needs to work well.
- Build an app: [Shiny](build.qmd) | [Streamlit](build-streamlit.qmd) | [Gradio](build-gradio.qmd) | [Dash](build-dash.qmd)
