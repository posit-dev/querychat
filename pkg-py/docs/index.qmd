---
title: Introduction
lightbox: true
---

```{=html}
<style>h1.title { display:none; }</style>
```

<img src="/images/querychat.png" alt="querychat website banner image" class="d-block mx-auto mb-3" style="max-width:100%; max-height:425px"/>

<p class="fs-2 lead mt-3 mb-3 text-center" style="max-width: 600px; margin: auto;">
Explore data using natural language queries
</p>

<div class="d-flex justify-content-center mb-3">
<!-- badges start -->
<a href="https://pypi.org/project/querychat/"><img alt="PyPI" src="https://img.shields.io/pypi/v/querychat?logo=python&logoColor=white&color=orange"></a>
<a href="https://choosealicense.com/licenses/mit/"><img src="https://img.shields.io/badge/License-MIT-blue.svg" alt="MIT License"></a>
<a href="https://pypi.org/project/querychat"><img src="https://img.shields.io/pypi/pyversions/querychat.svg" alt="versions"></a>
<a href="https://github.com/posit-dev/querychat"><img src="https://github.com/posit-dev/querychat/actions/workflows/py-test.yml/badge.svg?branch=main" alt="Python Tests"></a>
<!-- badges end -->
</div>

querychat facilitates safe and reliable natural language exploration of tabular data, powered by SQL and large language models (LLMs). For users, it offers an intuitive web application where they can quickly ask questions of their data and receive verifiable data-driven answers. As a developer, you can access the chat UI component, generated SQL queries, and filtered data to build custom applications that integrate natural language querying into your data workflows.

## Installation

Install the latest stable release [from PyPI](https://pypi.org/project/querychat/):

```bash
pip install querychat
```

## Quick start

The main entry point is the [`QueryChat` class](reference/QueryChat.qmd). It requires a [data source](data-sources.qmd) (e.g., pandas, polars, etc) and a name for the data. It also accepts optional parameters to customize the behavior, such as the `client` [model](models.qmd).
The quickest way to start chatting is to call the `.app()` method, which returns a Shiny app object.


```{.python filename="titanic-app.py"}
from querychat import QueryChat
from querychat.data import titanic

qc = QueryChat(titanic(), "titanic")
app = qc.app()
```

With an API key set[^api-key], you can run that code in a Python console and then call `app.run()` to jump into a chat. Or you can save the code to `titanic-app.py` and [run the app](https://shiny.posit.co/py/get-started/create-run.html#run-your-shiny-application) from a terminal (or Positron, or [VS Code](https://marketplace.visualstudio.com/items?itemName=Posit.shiny)):

```bash
# Optionally, change the default model:
export QUERYCHAT_CLIENT="anthropic/claude-sonnet-4-5"
# And provide appropriate credentials for your chosen model provider
export ANTHROPIC_API_KEY="your_api_key_here"
shiny run --reload titanic-app.py
```

[^api-key]: By default, querychat uses OpenAI to power the chat experience. So, for this example to work, you'll need [an OpenAI API key](https://platform.openai.com/). See the [Models](models.qmd) page for details on how to set up credentials for other model providers.

Once running, you'll notice 3 main views:

1. A sidebar chat with suggestions on where to start exploring.
2. A data table that updates to reflect filtering and sorting queries.
3. The SQL query behind the data table, for transparency and reproducibility.

![](/images/quickstart.png){fig-alt="Screenshot of querychat's app with the titanic dataset." class="lightbox shadow rounded mb-3"}

Suppose we pick a suggestion like "Show me passengers who survived". Since this is a filtering operation, both the data table and SQL query update accordingly.

![](/images/quickstart-filter.png){fig-alt="Screenshot of the querychat's app with the titanic dataset filtered to passengers who survived." class="lightbox shadow rounded mb-3"}

querychat can also handle more general questions about the data that require calculations and aggregations. For example, we can ask "What is the average age of passengers who survived?". The LLM will generate the SQL query to perform the calculation, querychat will execute it, and return the result in the chat:

![](/images/quickstart-summary.png){fig-alt="Screenshot of the querychat's app with a summary statistic inlined in the chat." class="lightbox shadow rounded mb-3"}

## Custom apps

querychat is designed to be highly extensible -- it provides programmatic access to the chat interface, the filtered/sorted data frame, SQL queries, and more.
This makes it easy to build custom web apps that leverage natural language interaction with your data.
For example, [here](https://github.com/posit-conf-2025/llm/blob/main/_solutions/25_querychat/25_querychat_02-end-app.R)'s a bespoke app for exploring Airbnb listings in Ashville, NC:

![](/images/airbnb.png){fig-alt="A custom app for exploring Airbnb listings, powered by querychat." class="lightbox shadow rounded mb-3"}

To learn more, see [Build an app](build.qmd) for a step-by-step guide.

## How it works

querychat leverages the incredible capabilities of large language models to translate natural language into SQL queries.
Models of all sizes, from small models you can run locally on your laptop to large frontier models by major AI providers, are all surprisingly good at this task.
That said, even the best models still need to know the overall data structure to perform well.
For this reason, QueryChat includes a description of the data's schema -- column names, types, ranges, categorical values -- in the LLM's [system prompt](context.qmd).
Note that QueryChat **does not** send the raw data itself to the model! 
Instead, it shares just enough of a description of the data that the model can reliably generate SQL queries.

When the LLM generates a query, querychat executes it against a SQL database (DuckDB[^duckdb] by default) to get results in a **safe**, **reliable**, and **verifiable** manner. 
In short, this execution is **safe** since only `SELECT` statements are allowed, **reliable** since the database engine handles all calculations, and **verifiable** since the user can always see the SQL query that was run.
This makes QueryChat a trustworthy tool for data exploration, as every action taken by the LLM is transparent and independently reproducible.

::: callout-important
### Data privacy

See the [Provide context](context.qmd) and [Tools](tools.qmd) articles to learn more about what information is provided to the LLM and what it's capable of doing with code execution.
::::

[^duckdb]: Duckdb is extremely fast and has a surprising number of [statistical functions](https://duckdb.org/docs/stable/sql/functions/aggregates.html#statistical-aggregates).


## Next steps

From here, you might want to learn more about:

- [Models](models.qmd): customize the LLM behind querychat.
- [Data sources](data-sources.qmd): different data sources you can use with querychat.
- [Provide context](context.qmd): provide the LLM with the context it needs to work well.
- [Build an app](build.qmd): design a custom Shiny app around querychat.
